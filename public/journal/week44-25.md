*"With foes ahead, behind us dread, Beneath the sky shall be our bed,*  
*Until at last our toil be passed, Our journey done, our errand sped.*  
*We must away! We must away! We ride before the break of day!"*  

## Mon, Oct 27 and Tue, Oct 28 | Job Applications and Speech recognition demo 
* applied to several companies  
* I used **whisper V3 Turbo**, an open source model by openAI. My project uses the transformers library from hugging face for easy access to the model and Gradio for easy demonstration. There are two options : to live transcribe or to upload an audio file. I used colab's T4 GPU. One version of the demo used flash attention and A100 GPU, which works fine too.  
* Some of the challenges that I overcame  
    * one of the challenges was to transcribe streaming audio  
    * Flash attention requires A100 GPU from Nvidia which requires Google Colab pro. T4 GPU and MPS not supported. Therefore, abandoning personal PC for the demo.  
    * Faster-whisper does not support Apple’s MPS.
    * Using whisper library directly v/s using Hugging face’s transformers library. Selected later.  
    * Running all the supporting files on github rather than the notebook alone.  
    * Setting up HF token to establish connection between the model hosted on HF and colab notebook  

## Wed, Oct 29 |  
* Engaging in lofty colour and design changes in the personal website which are not functionally required.


## Thur, Oct 30 |  


## Fri, Oct 31 |  


## Technologies Used
**Speech to Text**  
**OpenAI's Whisper**  
**Transformers**  


